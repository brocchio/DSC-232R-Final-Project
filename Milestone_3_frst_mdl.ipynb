{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02d81dbc-2fb4-4506-b494-ac991b364b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary cache directory at /scratch/brocchio/job_39796952/matplotlib-iao7xbdv because the default path (/home/jovyan/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import os, pickle, glob\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, count, mean, stddev, min, max, countDistinct, sum as spark_sum\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Imputer, VectorAssembler, StandardScaler\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorSlicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6041a255-7589-40be-925a-360d18eebd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    spark.stop()\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0626ae4b-ba3b-4c18-8f0b-c18d16b10567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark spill directory: /scratch/brocchio/job_39796952\n"
     ]
    }
   ],
   "source": [
    "spill_dir = os.environ[\"SLURM_TMPDIR\"]\n",
    "\n",
    "sc = SparkSession.builder \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"20g\") \\\n",
    "    .config(\"spark.executor.memoryOverhead\", \"4g\")\\\n",
    "    .config('spark.executor.instances', 2)\\\n",
    "    .config('spark.executor.cores', 4)\\\n",
    "    .config('spark.drive.cores', 4)\\\n",
    "    .config(\"spark.local.dir\", spill_dir)\\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark spill directory:\", spill_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbda374b-6ca5-4244-aa14-53fbc3fa7d32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = 'project_data/train.parquet/'\n",
    "df = sc.read.parquet(data_path)\n",
    "\n",
    "#df.printSchema()\n",
    "\n",
    "#df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf871cbb-cba9-4507-b6a4-2fe00bd25eff",
   "metadata": {},
   "source": [
    "## Pre-processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0707f377-85a0-45c7-ae05-a3ccc52095a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [c for c in df.columns if c.startswith(\"feature_\")]\n",
    "categorical_cols = [\"symbol_id\"]\n",
    "label_col = \"responder_7\"\n",
    "\n",
    "imputer = Imputer(strategy=\"median\", inputCols=feature_cols,\n",
    "                  outputCols=[f\"{c}_imputed\" for c in feature_cols])\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[*imputer.getOutputCols(), *categorical_cols],\n",
    "    outputCol=\"features_vec\"\n",
    ")\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features_vec\",\n",
    "                        outputCol=\"scaled_features\",\n",
    "                        withMean=True, withStd=True)\n",
    "\n",
    "pipeline_prep = Pipeline(stages=[imputer, assembler, scaler])\n",
    "prep_model = pipeline_prep.fit(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e6e03b-397d-430f-ab65-4c66688a409f",
   "metadata": {},
   "source": [
    "## Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b329bc7b-c365-4034-80a9-7b6e859c8191",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_features = assembler.getInputCols()\n",
    "feature_pos = {f: i for i, f in enumerate(all_features)}\n",
    "\n",
    "top5_names = [\n",
    "    \"feature_56_imputed\",\n",
    "    \"feature_45_imputed\",\n",
    "    \"feature_19_imputed\",\n",
    "    \"feature_66_imputed\",\n",
    "    \"feature_06_imputed\",\n",
    "]\n",
    "\n",
    "top5_idx = [feature_pos[i] for i in top5_names]\n",
    "\n",
    "slicer = VectorSlicer(\n",
    "    inputCol=\"scaled_features\",\n",
    "    outputCol=\"feat_vec\",\n",
    "    indices=top5_idx \n",
    ")\n",
    "\n",
    "linreg = LinearRegression(\n",
    "    featuresCol=\"feat_vec\",\n",
    "    labelCol=label_col,\n",
    "    maxIter=100,\n",
    "    regParam=0.01,\n",
    "    elasticNetParam=0.5\n",
    ")\n",
    "\n",
    "train_df = df.filter(\"date_id <= 1350\")\n",
    "val_df   = df.filter(\"date_id BETWEEN 1351 AND 1500\")\n",
    "test_df  = df.filter(\"date_id > 1500\")\n",
    "\n",
    "pipe_lr = Pipeline(stages=[prep_model, slicer, linreg])\n",
    "lr_model   = pipe_lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a87e176-7052-4e36-882e-8e6b054d5d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear‑Regression RMSE train 0.9351  | val 0.9274  | test 0.8065\n"
     ]
    }
   ],
   "source": [
    "evaluator = (RegressionEvaluator(labelCol=label_col,\n",
    "                                 predictionCol=\"prediction\",\n",
    "                                 metricName=\"rmse\"))\n",
    "\n",
    "pred_train = lr_model.transform(train_df)\n",
    "pred_val   = lr_model.transform(val_df)\n",
    "pred_test  = lr_model.transform(test_df)\n",
    "\n",
    "rmse_train = evaluator.evaluate(pred_train)\n",
    "rmse_val   = evaluator.evaluate(pred_val)\n",
    "rmse_test  = evaluator.evaluate(pred_test)\n",
    "\n",
    "print(f\"Linear‑Regression RMSE train {rmse_train:.4f}  | \"\n",
    "      f\"val {rmse_val:.4f}  | test {rmse_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0789df9c-5d0c-45c8-b93a-1b3798cc6c1c",
   "metadata": {},
   "source": [
    "## Random Forest Top 5 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adfdfcfc-2f18-4533-9ad3-920f0633076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = assembler.getInputCols()\n",
    "feature_pos = {f: i for i, f in enumerate(all_features)}\n",
    "\n",
    "top5_names = [\n",
    "    \"feature_56_imputed\",\n",
    "    \"feature_45_imputed\",\n",
    "    \"feature_19_imputed\",\n",
    "    \"feature_66_imputed\",\n",
    "    \"feature_06_imputed\",\n",
    "]\n",
    "\n",
    "top5_idx = [feature_pos[i] for i in top5_names]\n",
    "\n",
    "slicer = VectorSlicer(\n",
    "    inputCol=\"scaled_features\",\n",
    "    outputCol=\"feat_vec\",\n",
    "    indices=top5_idx \n",
    ")\n",
    "\n",
    "rf = (RandomForestRegressor(featuresCol=\"feat_vec\",\n",
    "                            labelCol=label_col,\n",
    "                            numTrees=30,\n",
    "                            maxDepth=4,\n",
    "                            subsamplingRate=0.6,\n",
    "                            featureSubsetStrategy=\"sqrt\",\n",
    "                            seed=42))\n",
    "\n",
    "pipe_rf5 = Pipeline(stages=[prep_model, slicer, rf])\n",
    "\n",
    "train_df = df.filter(\"date_id <= 1350\")\n",
    "val_df   = df.filter(\"date_id BETWEEN 1351 AND 1500\")\n",
    "test_df  = df.filter(\"date_id > 1500\")\n",
    "\n",
    "rf5_model = pipe_rf5.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5e0da4d-245e-4ad2-a8d9-44696cd916d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random‑Forest RMSE train 0.9349  | val 0.9270  | test 0.8063\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=label_col,\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"rmse\")\n",
    "\n",
    "pred_train = rf5_model.transform(train_df)\n",
    "pred_val   = rf5_model.transform(val_df)\n",
    "pred_test  = rf5_model.transform(test_df)\n",
    "\n",
    "rmse_train = evaluator.evaluate(pred_train)\n",
    "rmse_val   = evaluator.evaluate(pred_val)\n",
    "rmse_test  = evaluator.evaluate(pred_test)\n",
    "\n",
    "print(f\"Random‑Forest RMSE train {rmse_train:.4f}  | \"\n",
    "      f\"val {rmse_val:.4f}  | test {rmse_test:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
